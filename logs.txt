

sudo openconnect --protocol=gp --user=hyunho.mo@unitn.it https://vpn.icts.unitn.it/gateway






python3 inference_mlp.py -w 1 -s 1 -bs 512 -ep 60 -pt 10 -vs 0.1 -lr 0.001 -sub 1




trial1

The FLOPs is:188751
wind length_1,  win stride_1
# Training samples:  5263447
# Inference samples:  1253743
Training time:  1163.4503991603851
Inference time:  48.74464178085327
Result in RMSE:  6.44

wind length_1,  win stride_1
# Training samples:  5263447
# Inference samples:  1253743
Training time:  1099.9206492900848
Inference time:  32.534690141677856
Result in RMSE:  6.63

# Training samples:  5263447
# Inference samples:  1253743
Training time:  1081.05109500885
Inference time:  33.46583700180054
Result in RMSE:  6.81

# Training samples:  5263447
# Inference samples:  1253743
Training time:  1146.7189536094666
Inference time:  40.53121757507324
Result in RMSE:  7.25


# Training samples:  5263447
# Inference samples:  1253743
Training time:  863.9094729423523
Inference time:  40.75934672355652
Result in RMSE:  6.85


---


python3 inference_mlp.py -w 1 -s 1 -bs 512 -ep 60 -pt 10 -vs 0.1 -lr 0.001 -sub 50

# Training samples:  105272
# Inference samples:  25076
Training time:  18.473470449447632
Inference time:  2.6845107078552246
Result in RMSE:  6.65

# Training samples:  105272
# Inference samples:  25076
Training time:  22.965392351150513
Inference time:  2.647918462753296
Result in RMSE:  7.41

# Training samples:  105272
# Inference samples:  25076
Training time:  15.977369785308838
Inference time:  2.9868359565734863
Result in RMSE:  7.82

# Training samples:  105272
# Inference samples:  25076
Training time:  23.2527756690979
Inference time:  2.581916093826294
Result in RMSE:  6.82

# Training samples:  105272
# Inference samples:  25076
Training time:  15.923941612243652
Inference time:  2.3596901893615723
Result in RMSE:  7.48


------------
----------------------------------------------------------------




python3 inference_cnn_aggr.py -w 50 -s 1 -f 10 -k 10 -bs 256 -ep 60 -pt 10 -vs 0.1 -lr 0.001 -sub 1


The FLOPs is:311151
wind length_50,  win stride_1
# Training samples:  5263153
# Inference samples:  1253596
Training time:  3169.3944182395935
Inference time:  150.39525890350342
Result in RMSE:  6.47


The FLOPs is:311151
wind length_50,  win stride_1
# Training samples:  5263153
# Inference samples:  1253596
Training time:  1969.5235471725464
Inference time:  166.81573104858398
Result in RMSE:  6.29

wind length_50,  win stride_1
# Training samples:  5263153
# Inference samples:  1253596
Training time:  1783.244820356369
Inference time:  168.96382308006287
Result in RMSE:  6.57

# Training samples:  5263153
# Inference samples:  1253596
Training time:  2250.7660822868347
Inference time:  145.57169365882874
Result in RMSE:  6.3


wind length_50,  win stride_1
# Training samples:  5263153
# Inference samples:  1253596
Training time:  2437.5590608119965
Inference time:  121.45044732093811
Result in RMSE:  6.04


python3 inference_cnn_aggr.py -w 50 -s 50 -f 10 -k 10 -bs 128 -ep 60 -pt 10 -vs 0.1 -lr 0.001 -sub 1

The FLOPs is:311151
wind length_50,  win stride_50
# Training samples:  105266
# Inference samples:  25073
Training time:  134.21058058738708
Inference time:  4.237070322036743
Result in RMSE:  6.92

The FLOPs is:311151
wind length_50,  win stride_50
# Training samples:  105266
# Inference samples:  25073
Training time:  142.0975489616394
Inference time:  4.290865898132324
Result in RMSE:  6.58

wind length_50,  win stride_50
# Training samples:  105266
# Inference samples:  25073
Training time:  144.72168946266174
Inference time:  4.655816555023193
Result in RMSE:  7.41

wind length_50,  win stride_50
# Training samples:  105266
# Inference samples:  25073
Training time:  84.41433882713318
Inference time:  4.8325581550598145
Result in RMSE:  6.92


wind length_50,  win stride_50
# Training samples:  105266
# Inference samples:  25073
Training time:  70.30952382087708
Inference time:  1.4977712631225586
Result in RMSE:  7.14

-----------------------------

python3 inference_cnnlstm.py -w 50 -s 50 -f 5 -k 5 -bs 256 -ep 40 -pt 10 -lr 0.001 -vs 0.1 -sub 1 -s_stride 1 -s_len 20 -n_conv 2 -lstm1 8 -lstm2 4


The FLOPs is:7028089
wind length_50,  win stride_50
# Training samples:  105266
# Inference samples:  25073
Training time:  913.0022358894348
Inference time:  82.57913088798523
Result in RMSE:  9.61


python3 inference_cnnlstm.py -w 50 -s 50 -f 3 -k 3 -bs 256 -ep 40 -pt 10 -lr 0.001 -vs 0.1 -sub 1 -s_stride 1 -s_len 20 -n_conv 1 -lstm1 8 -lstm2 4


wind length_50,  win stride_50
# Training samples:  105266
# Inference samples:  25073
Training time:  412.174521446228
Inference time:  36.4867844581604
Result in RMSE:  8.93


--

python3 inference_cnnlstm.py -w 50 -s 50 -f 10 -k 10 -bs 128 -ep 40 -pt 10 -lr 0.001 -vs 0.1 -sub 1 -s_stride 1 -s_len 30 -n_conv 2 -lstm1 10 -lstm2 5


python3 inference_cnnlstm.py -w 50 -s 50 -f 10 -k 10 -bs 128 -ep 40 -pt 10 -lr 0.001 -vs 0.1 -sub 1 -s_stride 1 -s_len 30 -n_conv 2 -lstm1 10 -lstm2 5


The FLOPs is:38925824
wind length_50,  win stride_50
# Training samples:  105266
# Inference samples:  25073
Training time:  1811.366604566574
Inference time:  80.33268356323242
Result in RMSE:  6.61

The FLOPs is:38925824
wind length_50,  win stride_50
# Training samples:  105266
# Inference samples:  25073
Training time:  1394.2559411525726
Inference time:  70.44587683677673
Result in RMSE:  9.85


python3 inference_cnnlstm.py -w 50 -s 50 -f 5 -k 5 -bs 128 -ep 40 -pt 10 -lr 0.001 -vs 0.1 -sub 1 -s_stride 1 -s_len 30 -n_conv 1 -lstm1 10 -lstm2 5

The FLOPs is:6416324
wind length_50,  win stride_50
# Training samples:  105266
# Inference samples:  25073
Training time:  605.9146420955658
Inference time:  57.215771198272705
Result in RMSE:  9.42

python3 inference_cnnlstm.py -w 50 -s 50 -f 5 -k 5 -bs 128 -ep 40 -pt 10 -lr 0.0001 -vs 0.1 -sub 1 -s_stride 1 -s_len 30 -n_conv 1 -lstm1 10 -lstm2 5

The FLOPs is:6416324
wind length_50,  win stride_50
# Training samples:  105266
# Inference samples:  25073
Training time:  954.8707702159882
Inference time:  57.56718921661377
Result in RMSE:  6.8

The FLOPs is:6416324
wind length_50,  win stride_50
# Training samples:  105266
# Inference samples:  25073
Training time:  946.9784746170044
Inference time:  57.34971475601196
Result in RMSE:  7.54


The FLOPs is:6416324
wind length_50,  win stride_50
# Training samples:  105266
# Inference samples:  25073
Training time:  975.4682562351227
Inference time:  59.138495683670044
Result in RMSE:  6.65

The FLOPs is:6416324
wind length_50,  win stride_50
# Training samples:  105266
# Inference samples:  25073
Training time:  1014.7675285339355
Inference time:  57.34765911102295
Result in RMSE:  6.37

The FLOPs is:6416324
wind length_50,  win stride_50
# Training samples:  105266
# Inference samples:  25073
Training time:  957.303953409195
Inference time:  46.04826259613037
Result in RMSE:  6.9



------------
python3 inference_cnnlstm.py -w 50 -s 50 -f 3 -k 3 -bs 128 -ep 40 -pt 10 -lr 0.0001 -vs 0.1 -sub 1 -s_stride 1 -s_len 30 -n_conv 1 -lstm1 10 -lstm2 5

Total params: 1,822,546
Trainable params: 1,822,426
Non-trainable params: 120



The FLOPs is:3946524
wind length_50,  win stride_50
# Training samples:  105266
# Inference samples:  25073
Training time:  938.5350296497345
Inference time:  52.53566336631775
Result in RMSE:  6.17

The FLOPs is:3946524
wind length_50,  win stride_50
# Training samples:  105266
# Inference samples:  25073
Training time:  1136.0317833423615
Inference time:  60.66401672363281
Result in RMSE:  6.21

wind length_50,  win stride_50
# Training samples:  105266
# Inference samples:  25073
Training time:  1195.629662513733
Inference time:  51.71595621109009
Result in RMSE:  7.14

wind length_50,  win stride_50
# Training samples:  105266
# Inference samples:  25073
Training time:  892.1474990844727
Inference time:  43.82914352416992
Result in RMSE:  7.3

wind length_50,  win stride_50
# Training samples:  105266
# Inference samples:  25073
Training time:  911.4515697956085
Inference time:  59.41418242454529
Result in RMSE:  6.37

----
python3 inference_cnnlstm.py -w 50 -s 50 -f 1 -k 1 -bs 128 -ep 40 -pt 10 -lr 0.0001 -vs 0.1 -sub 1 -s_stride 1 -s_len 30 -n_conv 1 -lstm1 10 -lstm2 5

The FLOPs is:1678324
wind length_50,  win stride_50
# Training samples:  105266
# Inference samples:  25073
Training time:  2094.370660305023
Inference time:  56.93394899368286
Result in RMSE:  8.58
--


python3 inference_lstm_aggr.py -w 50 -s 50 -f 10 -k 10 -bs 128 -ep 50 -pt 20 -vs 0.1 -lr 0.001 -sub 1 -l1 200 -l2 100

None


------
python3 inference_cnn_aggr.py -w 50 -s 1 -f 10 -k 10 -bs 1024 -ep 30 -pt 5 -vs 0.1 -lr 0.001 -sub 1

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d (Conv1D)              (None, 50, 10)            2010      
_________________________________________________________________
activation (Activation)      (None, 50, 10)            0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 50, 10)            1010      
_________________________________________________________________
activation_1 (Activation)    (None, 50, 10)            0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 50, 1)             101       
_________________________________________________________________
activation_2 (Activation)    (None, 50, 1)             0         
_________________________________________________________________
flatten (Flatten)            (None, 50)                0         
_________________________________________________________________
dense (Dense)                (None, 50)                2550      
_________________________________________________________________
activation_3 (Activation)    (None, 50)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 51        
_________________________________________________________________
activation_4 (Activation)    (None, 1)                 0         
=================================================================
Total params: 5,722
Trainable params: 5,722
Non-trainable params: 0



The FLOPs is:316201
wind length_50,  win stride_1
# Training samples:  5263153
# Inference samples:  1253596
Training time:  607.8749282360077
Inference time:  175.1513340473175
Result in RMSE:  6.41

The FLOPs is:316201
wind length_50,  win stride_1
# Training samples:  5263153
# Inference samples:  1253596
Training time:  413.24906969070435
Inference time:  227.53945922851562
Result in RMSE:  5.79

The FLOPs is:316201
wind length_50,  win stride_1
# Training samples:  5263153
# Inference samples:  1253596
Training time:  655.5488197803497
Inference time:  185.9107050895691
Result in RMSE:  6.4

The FLOPs is:316201
wind length_50,  win stride_1
# Training samples:  5263153
# Inference samples:  1253596
Training time:  374.1161558628082
Inference time:  186.19594287872314
Result in RMSE:  6.22

The FLOPs is:316201
wind length_50,  win stride_1
# Training samples:  5263153
# Inference samples:  1253596
Training time:  464.5009346008301
Inference time:  171.41551899909973
Result in RMSE:  6.76


------
python3 inference_cnn_aggr.py -w 50 -s 1 -f 10 -k 10 -bs 1024 -ep 30 -pt 5 -vs 0.1 -lr 0.001 -sub 1

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d (Conv1D)              (None, 50, 10)            2010      
_________________________________________________________________
activation (Activation)      (None, 50, 10)            0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 50, 10)            1010      
_________________________________________________________________
activation_1 (Activation)    (None, 50, 10)            0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 50, 1)             101       
_________________________________________________________________
activation_2 (Activation)    (None, 50, 1)             0         
_________________________________________________________________
flatten (Flatten)            (None, 50)                0         
_________________________________________________________________
dense (Dense)                (None, 50)                2550      
_________________________________________________________________
activation_3 (Activation)    (None, 50)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 51        
_________________________________________________________________
activation_4 (Activation)    (None, 1)                 0         
=================================================================
Total params: 5,722
Trainable params: 5,722
Non-trainable params: 0


The FLOPs is:316201
wind length_50,  win stride_1
# Training samples:  5263153
# Inference samples:  1253596
Training time:  481.82790064811707
Inference time:  192.6196575164795
Result in RMSE:  6.74







------------------

python3 inference_cnn_aggr.py -w 50 -s 1 -f 20 -k 10 -bs 1024 -ep 30 -pt 5 -vs 0.1 -lr 0.001 -sub 1

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d (Conv1D)              (None, 50, 20)            4020      
_________________________________________________________________
activation (Activation)      (None, 50, 20)            0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 50, 20)            4020      
_________________________________________________________________
activation_1 (Activation)    (None, 50, 20)            0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 50, 1)             201       
_________________________________________________________________
activation_2 (Activation)    (None, 50, 1)             0         
_________________________________________________________________
flatten (Flatten)            (None, 50)                0         
_________________________________________________________________
dense (Dense)                (None, 50)                2550      
_________________________________________________________________
activation_3 (Activation)    (None, 50)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 51        
_________________________________________________________________
activation_4 (Activation)    (None, 1)                 0         
=================================================================
Total params: 10,842
Trainable params: 10,842
Non-trainable params: 0
_____________________________

The FLOPs is:827201
wind length_50,  win stride_1
# Training samples:  5263153
# Inference samples:  1253596
Training time:  705.665456533432
Inference time:  223.54039072990417
Result in RMSE:  7.06
_


The FLOPs is:827201
wind length_50,  win stride_1
# Training samples:  5263153
# Inference samples:  1253596
Training time:  398.14663219451904
Inference time:  188.96166396141052
Result in RMSE:  6.69

(no random)
python3 inference_cnn_aggr.py -w 50 -s 1 -f 10 -k 10 -bs 1024 -ep 50 -pt 10 -vs 0.1 -lr 0.001 -sub 1

Layer (type)                 Output Shape              Param #   
=================================================================
conv1d (Conv1D)              (None, 50, 10)            2010      
_________________________________________________________________
activation (Activation)      (None, 50, 10)            0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 50, 10)            1010      
_________________________________________________________________
activation_1 (Activation)    (None, 50, 10)            0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 50, 1)             101       
_________________________________________________________________
activation_2 (Activation)    (None, 50, 1)             0         
_________________________________________________________________
flatten (Flatten)            (None, 50)                0         
_________________________________________________________________
dense (Dense)                (None, 50)                2550      
_________________________________________________________________
activation_3 (Activation)    (None, 50)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 51        
_________________________________________________________________
activation_4 (Activation)    (None, 1)                 0         
=================================================================
Total params: 5,722
Trainable params: 5,722
Non-trainable params: 0



The FLOPs is:316201
wind length_50,  win stride_1
# Training samples:  5263153
# Inference samples:  1253596
Training time:  255.15105366706848
Inference time:  207.53027749061584
Result in RMSE:  5.98

The FLOPs is:316201
wind length_50,  win stride_1
# Training samples:  5263153
# Inference samples:  1253596
Training time:  271.5106258392334
Inference time:  171.3393635749817
Result in RMSE:  5.72

The FLOPs is:316201
wind length_50,  win stride_1
# Training samples:  5263153
# Inference samples:  1253596
Training time:  273.2136914730072
Inference time:  210.18060684204102
Result in RMSE:  5.5


The FLOPs is:316201
wind length_50,  win stride_1
# Training samples:  5263153
# Inference samples:  1253596
Training time:  346.79398560523987
Inference time:  161.0526168346405
Result in RMSE:  5.93

The FLOPs is:316201
wind length_50,  win stride_1
# Training samples:  5263153
# Inference samples:  1253596
Training time:  410.06535148620605
Inference time:  181.4243414402008
Result in RMSE:  5.51




---
python3 inference_lstm_aggr.py -w 50 -s 1 -f 10 -k 10 -bs 1024 -ep 30 -pt 5 -vs 0.1 -lr 0.001 -sub 1 -l1 200 -l2 100 

Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 50, 200)           176800    
_________________________________________________________________
dropout (Dropout)            (None, 50, 200)           0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 100)               120400    
_________________________________________________________________
dropout_1 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense (Dense)                (None, 1)                 101       
_________________________________________________________________
activation (Activation)      (None, 1)                 0         
=================================================================
Total params: 297,301
Trainable params: 297,301
Non-trainable params: 0


The FLOPs is:594309
wind length_50,  win stride_1
# Training samples:  5263153
# Inference samples:  1253596
Training time:  5839.377256155014
Inference time:  269.13259053230286
Result in RMSE:  5.56

The FLOPs is:594309
wind length_50,  win stride_1
# Training samples:  5263153
# Inference samples:  1253596
Training time:  4372.0528700351715
Inference time:  253.91949820518494
Result in RMSE:  5.48


The FLOPs is:594309
wind length_50,  win stride_1
# Training samples:  5263153
# Inference samples:  1253596
Training time:  4137.580518007278
Inference time:  232.0687072277069
Result in RMSE:  5.36

The FLOPs is:594309
wind length_50,  win stride_1
# Training samples:  5263153
# Inference samples:  1253596
Training time:  4260.436011791229
Inference time:  287.01993703842163
Result in RMSE:  5.79

####################à
ga_elm1.mean() rmse 7.264
ga_elm1.mean() params 3411.0
ga_elm1.mean() p2 1846.0
ga_elm1.mean() p3 1559.0
ga_elm1.mean() time 16.187694444444443
ga_elm1.mean() training_time 337.0
ga_elm1.std() rmse 0.05460972644339292
ga_elm1.std() params 210.6313261496389
ga_elm1.std() p2 63.63087999461337
ga_elm1.std() p3 169.14490828872147
ga_elm1.std() time 1.6762955344939434
ga_elm1.std() training_time 48.94668301098429
ga_elm2.mean() rmse 7.214
ga_elm2.mean() params 1863.0
ga_elm2.mean() p2 1750.0
ga_elm2.mean() p3 111.0
ga_elm2.mean() time 9.671722222222224
ga_elm2.mean() training_time 110.1
ga_elm2.std() rmse 0.044271887242357255
ga_elm2.std() params 208.1692687320692
ga_elm2.std() p2 218.63211109075445
ga_elm2.std() p3 153.43836982102403
ga_elm2.std() time 0.44533504133380336
ga_elm2.std() training_time 22.471957833906885
len(results_df) 28
moo results_df.mean() rmse 7.294642857142857
results_df.mean() params 898.2142857142857
results_df.mean() p2 81.96428571428571
results_df.mean() p3 7.571428571428571
results_df.mean() f1 6.839591235
results_df.mean() f2 898.2142857142857
results_df.mean() train_time 55.266223839351106
moo results_df.std() rmse 0.070104796837895
results_df.std() params 60.31114210851808
results_df.std() p2 8.243885019312206
results_df.std() p3 6.746349198879904
results_df.std() f1 0.04494121335570692
results_df.std() train_time 10.118870413665602
moo_time_avg 0.13888888888888884
moo_time_std 5.972222222222221


#######2022########

gen     nevals  avg             std             min             max      
0       50      [7.116506]      [0.94330373]    [6.2383]        [10.2419]
population saved
pickle dump
log saved
Best individual:
[5, 22, 27, 39]
[[5, 22, 27, 39]]
Best individual is saved
EA time:  6015.53161406517


###########
5
Topk_obs_pred_rmse 1.7147
Topk_obs_mid_rmse 3.071
rho_pred 0.5776671408250356
pval_pred 5.756814977907376e-08
rho_obsn 0.788108108108108
pval_obsn 4.833774583014055e-17

15
Topk_obs_pred_rmse 0.683
Topk_obs_mid_rmse 1.3627
rho_pred 0.7157716179255207
pval_pred 1.7339059977993237e-16
rho_obsn 0.29407742478434673
pval_obsn 0.003458745370525646

10
Topk_obs_pred_rmse 0.8382
Topk_obs_mid_rmse 1.12
rho_pred 0.6430497973274971
pval_pred 4.792185860735202e-12
rho_obsn 0.7655163910423377
pval_obsn 6.319378242738529e-19

top 50
rho_pred 0.6430497973274971
pval_pred 4.792185860735202e-12
rho_obsn 0.7655163910423377
pval_obsn 6.319378242738529e-19
top k rho_pred 0.14362545018007203
top k pval_pred 0.319702499972949
top k rho_obsn 0.1872268907563025
top k pval_obsn 0.19293115958816123

top 10
Topk_obs_pred_rmse 0.9936
Topk_obs_mid_rmse 1.0576
rho_pred 0.6430497973274971
pval_pred 4.792185860735202e-12
rho_obsn 0.7655163910423377
pval_obsn 6.319378242738529e-19
top k rho_pred 0.3939393939393939
top k pval_pred 0.25999776683488757
top k rho_obsn 0.33333333333333326
top k pval_obsn 0.34659350708733405

14
len(rank_df) 99
len(rank_df) 97
Topk_obs_pred_rmse 0.5838
Topk_obs_mid_rmse 0.7881
rho_pred 0.8188381022512098
pval_pred 1.2443903365986498e-24
rho_obsn 0.7835709025878392
pval_obsn 2.3926087352730593e-21

top 50
Topk_obs_pred_rmse 0.6706
Topk_obs_mid_rmse 0.8198
rho_pred 0.8188381022512098
pval_pred 1.2443903365986498e-24
rho_obsn 0.7835709025878392
pval_obsn 2.3926087352730593e-21
top k rho_pred 0.5459303721488595
top k pval_pred 4.119796503086483e-05
top k rho_obsn 0.26837935174069627
top k pval_obsn 0.05950225010467334

top 10
Topk_obs_pred_rmse 0.7103
Topk_obs_mid_rmse 0.8589
rho_pred 0.8188381022512098
pval_pred 1.2443903365986498e-24
rho_obsn 0.7835709025878392
pval_obsn 2.3926087352730593e-21
top k rho_pred 0.7212121212121211
top k pval_pred 0.018573155089460208
top k rho_obsn 0.5636363636363636
top k pval_obsn 0.08972402831709125

13
Topk_obs_pred_rmse 0.5981
Topk_obs_mid_rmse 0.5613
rho_pred 0.796703743895822
pval_pred 2.836828573348312e-22
rho_obsn 0.8579625610417797
pval_obsn 6.120904863790829e-29

----------
python3 inference_cnnlstm.py -w 50 -s 50 -f 3 -k 3 -bs 128 -ep 40 -pt 10 -lr 0.0001 -vs 0.1 -sub 1 -s_stride 1 -s_len 30 -n_conv 1 -lstm1 10 -lstm2 5


python3 inference_cnnlstm.py -w 50 -s 50 -f 3 -k 3 -bs 256 -ep 40 -pt 10 -lr 0.001 -vs 0.1 -sub 1 -s_stride 1 -s_len 30 -n_conv 1 -lstm1 10 -lstm2 5


The FLOPs is:316201
wind length_50,  win stride_50
# Training samples:  84212
# Inference samples:  25073
Training time:  48.70258069038391
Inference time:  1.4080333709716797
score 27740.422057564814
Result in RMSE:  8.03

population [[9, 30, 28, 4], [9, 30, 28, 4], [9, 30, 28, 46], [9, 30, 28, 46], [9, 30, 28, 46], [9, 30, 28, 46], [10, 30, 30, 39], [10, 30, 30, 39], [10, 30, 30, 39], [10, 30, 30, 39], [10, 30, 30, 39], [10, 30, 30, 39], [10, 30, 30, 39], [10, 30, 30, 39], [10, 30, 30, 39], [10, 30, 30, 39], [10, 30, 30, 39], [10, 30, 30, 39], [10, 30, 30, 39], [10, 30, 30, 39], [10, 30, 30, 39], [10, 30, 30, 39], [10, 30, 30, 39], [10, 30, 30, 39], [10, 30, 30, 39], [10, 30, 30, 39], [10, 30, 30, 39], [10, 30, 30, 39], [10, 30, 25, 39], [10, 30, 30, 39]]
[6.1766, 6.1766, 6.1804, 6.1804, 6.1804, 6.1804, 6.1888, 6.1888, 6.1888, 6.1888, 6.1888, 6.1888, 6.1888, 6.1888, 6.1888, 6.1888, 6.1888, 6.1888, 6.1888, 6.1888, 6.1888, 6.1888, 6.1888, 6.1888, 6.1888, 6.1888, 6.1888, 6.1888, 6.2154, 6.1888]
min: 6.1766, max:6.2154, avg:6.18775333333333
30      7       [6.18775333]    [0.00646688]    [6.1766]        [6.2154]
pickle dump
log saved
Best individual:
hof [[9, 30, 28, 4]]
hof[0] [9, 30, 28, 4]
Best individual is saved
EA time:  72591.68201637268
####################  EA COMPLETE / HOF TEST   ##############################

BEST ind test RMSE 6.31
Average test RMSE 6.3309999999999995
BEST ind test score 18844.34
Average test score 18951.495666666666
-----------------

python3 -W ignore enas_elm.py -w 1 -s 1 -vs 0.2 --pop 1 --gen 1


python3 -W ignore enas_elm.py -w 1 -s 1 -vs 0.2 --pop 3 --gen 3 -bs 50000

python3 -W ignore enas_elm.py -w 1 -s 1 -vs 0.2 -constant 0.0001 --pop 2 --gen 2 -bs 50000

python3 -W ignore enas_elm.py -w 1 -s 1 -vs 0.2 -constant 0.0001 --pop 30 --gen 30 -bs 50000

python3 -W ignore enas_elm.py -w 1 -s 1 -vs 0.2 -constant 0.0001 --pop 20 --gen 20 -bs 50000

python3 -W ignore enas_elm_moo.py -w 1 -s 1 -vs 0.2 -constant 0.0001 --pop 8 --gen 10 -bs 50000 --obj "moo"

.settings/
python3 -W ignore elm_test.py -w 1 -s 1 -vs 0.2 -constant 0.0001 --pop 28 --gen 30 -bs 50000 --obj "moo"


python3 -W ignore enas_elm_moo.py -w 1 -s 1 -vs 0.2 -constant 0.0001 --pop 32 --gen 30 -bs 50000 --obj "moo"

python3 -W ignore enas_elm_moo.py -w 1 -s 1 -vs 0.2 -constant 0.0001 --pop 28 --gen 30 -bs 50000 --obj "moo"

python3 elm_params_time.py -w 1 -s 1 -vs 0.2 -constant 0.0001 -bs 50000


python3 -W ignore enas_elm_moo.py -w 1 -s 1 -vs 0.2 -constant 0.0001 --pop 28 --gen 30 -bs 10000 --obj "moo" -t 1

python3 -W ignore enas_elm.py -w 1 -s 1 -vs 0.2 -constant 0.0001 --pop 30 --gen 30 -bs 50000 --obj "soo" -t 2


python3 -W ignore elm_test_multi.py -w 1 -s 1 -vs 0.2 -constant 0.0001 --pop 28 --gen 30 -bs 50000 --obj "moo"


python3 enas_cnn_baseline.py -w 50 -s 50 -bs 500 -ep 50 -pt 10 -vs 0.2 -t 0 --pop 50 --gen 0 --obj "soo"

python3 val_test_acc.py -w 50 -s 50 -bs 500 -ep 50 -pt 10 -vs 0.2 -t 0 --pop 10 --gen 0 --obj "soo"

python3 enas_cnn_baseline.py -w 50 -s 50 -bs 512 -ep 50 -pt 20 -vs 0.2 -t 0 --pop 200 --gen 0 --obj "soo"

python3 val_test_acc.py -w 50 -s 50 -bs 512 -ep 50 -pt 10 -vs 0.2 -t 0 --pop 200 --gen 0 --obj "soo"

python3 val_test_acc.py -w 50 -s 50 -bs 512 -ep 30 -pt 30 -vs 0.2 -t 0 --pop 200 --gen 0 --obj "soo"

python3 val_test_acc_temp.py -w 50 -s 50 -bs 512 -ep 30 -pt 30 -vs 0.2 -t 0 --pop 200 --gen 0 --obj "soo"

python3 val_test_acc_plot.py -w 50 -s 50 -bs 512 -ep 30 -pt 30 -vs 0.2 -t 0 --pop 200 --gen 0 --obj "soo" --sch 1

python3 val_test_acc.py -w 50 -s 50 -bs 512 -ep 30 -pt 30 -vs 0.2 -t 0 --pop 100 --gen 0 --obj "soo"

python3 val_score.py -w 50 -s 50 -bs 512 -ep 50 -pt 10 -vs 0.2 -t 0 --pop 100 --gen 0 --obj "soo"

python3 val_score.py -w 50 -s 50 -bs 256 -ep 50 -pt 10 -vs 0.2 -t 0 --pop 200 --gen 0 --obj "soo"

python3 enas_cnn_baseline.py -w 50 -s 50 -bs 512 -ep 30 -pt 10 -vs 0.2 -t 0 --pop 200 --gen 0 --obj "soo"

python3 enas_cnn_baseline.py -w 50 -s 50 -bs 512 -ep 30 -pt 30 -vs 0.2 -t 0 --pop 100 --gen 0 --obj "soo"

python3 val_score.py -w 50 -s 50 -bs 512 -ep 50 -pt 10 -vs 0.2 -t 0 --pop 100 --gen 0 --obj "soo"

python3 plot_rmse_score.py --pop 200 --gen 0 -t 0 --bs 256



------------------------------------------------------------
MOO without accel

paretofront [[10, 30, 28, 8], [10, 30, 22, 3], [10, 21, 30, 27], [10, 21, 30, 16], [10, 21, 30, 1], [7, 28, 17, 5], [10, 21, 9, 5], [6, 30, 6, 8], [2, 18, 30, 27], [10, 9, 21, 8], [3, 14, 27, 5], [8, 7, 22, 7], [3, 9, 26, 8], [5, 7, 22, 3], [7, 5, 30, 1], [3, 5, 23, 3], [3, 5, 23, 1], [2, 18, 5, 3], [2, 18, 5, 1]]
hv 6811319.832599999
population saved
population [[2, 18, 5, 1], [2, 18, 5, 1], [10, 30, 28, 8], [10, 30, 28, 8], [3, 5, 23, 1], [2, 18, 5, 3], [10, 30, 22, 3], [7, 28, 17, 5], [10, 21, 30, 27], [10, 21, 9, 5], [10, 21, 30, 1], [3, 14, 27, 5], [3, 5, 23, 3], [7, 5, 30, 1], [6, 30, 6, 8], [10, 21, 30, 16], [3, 21, 9, 13], [2, 18, 5, 3], [6, 30, 6, 8], [10, 5, 28, 8]]
[19.2584, 19.2584, 6.2049, 6.2049, 8.4205, 18.4767, 6.2214, 6.2758, 6.2273, 6.372, 6.2724, 6.7736, 8.0421, 7.4622, 6.5709, 6.2699, 7.2736, 18.4767, 6.5709, 7.3988]
min: 6.2049, max:19.2584, avg:9.20157
20      11      [9.20157e+00 6.25043e+04]       [4.87569275e+00 7.44754545e+04] [   6.2049 2430.    ]   [1.92584e+01 2.23672e+05]
prft_df_trans      0   1   2   3
0   10  30  28   8
1   10  30  22   3
2   10  21  30  27
3   10  21  30  16
4   10  21  30   1
5    7  28  17   5
6   10  21   9   5
7    6  30   6   8
8    2  18  30  27
9   10   9  21   8
10   3  14  27   5
11   8   7  22   7
12   3   9  26   8
13   5   7  22   3
14   7   5  30   1
15   3   5  23   3
16   3   5  23   1
17   2  18   5   3
18   2  18   5   1
prft_path /home/hyunho/hmo/ACC_NAS/EA_log/prft_out_20_20_0.csv
pickle dump
log saved
Best individual:
hof [[10, 30, 28, 8]]
hof[0] [10, 30, 28, 8]
[[10, 30, 28, 8], [10, 30, 22, 3], [10, 21, 30, 27], [10, 21, 30, 16], [10, 21, 30, 1], [7, 28, 17, 5], [10, 21, 9, 5], [6, 30, 6, 8], [2, 18, 30, 27], [10, 9, 21, 8], [3, 14, 27, 5], [8, 7, 22, 7], [3, 9, 26, 8], [5, 7, 22, 3], [7, 5, 30, 1], [3, 5, 23, 3], [3, 5, 23, 1], [2, 18, 5, 3], [2, 18, 5, 1]]
Best individual is saved
EA time:  34400.26432108879

---------------------------------------------------------


hv 2698148.5128
population saved
population [[1, 22, 5, 1], [1, 22, 5, 1], [9, 25, 21, 7], [6, 5, 5, 1], [8, 5, 5, 1], [8, 14, 23, 7], [9, 22, 21, 7], [10, 20, 12, 7], [9, 25, 11, 16], [6, 5, 11, 7], [6, 13, 5, 6], [9, 21, 5, 7], [8, 22, 25, 7], [9, 25, 11, 16], [6, 22, 5, 6], [9, 22, 25, 7], [6, 5, 5, 1], [9, 5, 5, 1], [8, 21, 5, 7], [9, 22, 25, 7]]
[22.8293, 22.8293, 6.1834, 21.191, 9.7861, 6.4933, 6.3399, 6.3553, 6.3417, 8.0684, 6.9836, 6.5633, 6.2806, 6.3417, 6.8899, 6.2695, 21.191, 9.0225, 6.5718, 6.2695]
min: 6.1834, max:22.8293, avg:9.940055000000001
20      8       [9.940055e+00 3.835400e+04]     [6.11813381e+00 3.84139561e+04] [  6.1834 622.    ]     [2.28293e+01 1.06742e+05]
prft_df_trans      0   1   2   3
0    9  25  21   7
1    9  22  25   7
2    8  22  25   7
3    9  22  21   7
4    9  25  11  16
5   10  20  12   7
6    8  16  23   7
7    8  14  23   7
8    6  21  11  16
9    9  21   5   7
10   8  21   5   7
11   6  21   5   6
12   8  16   5   6
13  10  13   5   6
14   4   8  25   7
15   6  13   5   6
16   6   5  25   2
17   6   5  11   7
18   4   8   5   8
19   9   5   5   1
20   8   5   5   1
21   6   5   5   1
22   1  22  25   2
23   1   5   5   1
24   1  22   5   1
prft_path /home/hyunho/hmo/ACC_NAS/EA_log/prft_out_ori_20_20_0_30.csv
pickle dump
log saved
Best individual:
hof [[9, 25, 21, 7]]
hof[0] [9, 25, 21, 7]
[[9, 25, 21, 7], [9, 22, 25, 7], [8, 22, 25, 7], [9, 22, 21, 7], [9, 25, 11, 16], [10, 20, 12, 7], [8, 16, 23, 7], [8, 14, 23, 7], [6, 21, 11, 16], [9, 21, 5, 7], [8, 21, 5, 7], [6, 21, 5, 6], [8, 16, 5, 6], [10, 13, 5, 6], [4, 8, 25, 7], [6, 13, 5, 6], [6, 5, 25, 2], [6, 5, 11, 7], [4, 8, 5, 8], [9, 5, 5, 1], [8, 5, 5, 1], [6, 5, 5, 1], [1, 22, 25, 2], [1, 5, 5, 1], [1, 22, 5, 1]]
Best individual is saved
EA time:  36317.88621926308


-------------

paretofront [[4, 5, 25, 2], [3, 5, 25, 2], [2, 5, 14, 5], [2, 5, 11, 5], [3, 5, 5, 2], [1, 22, 25, 2], [1, 22, 10, 2], [1, 20, 5, 2], [1, 22, 5, 2]]
hv 4822776.1036
population saved
population [[1, 22, 5, 2], [1, 22, 5, 2], [4, 5, 25, 2], [4, 5, 25, 2], [2, 5, 11, 5], [3, 5, 25, 2], [3, 5, 5, 2], [2, 5, 14, 5], [2, 5, 14, 5], [1, 22, 25, 2], [1, 22, 10, 2], [3, 5, 5, 2], [1, 22, 10, 2], [1, 22, 5, 2], [1, 22, 5, 2], [1, 22, 5, 2], [1, 22, 5, 2], [2, 5, 14, 5], [2, 5, 14, 5], [2, 5, 14, 5]]
[22.7508, 22.7508, 5.5118, 5.5118, 20.018, 6.7041, 20.1705, 13.8634, 13.8634, 22.3606, 22.4519, 20.1705, 22.4519, 22.7508, 22.7508, 22.7508, 22.7508, 13.8634, 13.8634, 13.8634]
min: 5.5118, max:22.7508, avg:17.558645000000006
20      7       [  17.558645 2629.75    ]       [   6.03629761 1503.13877852]   [   5.5118 1142.    ]   [  22.7508 4932.    ]    
prft_df_trans    0   1   2  3
0  4   5  25  2
1  3   5  25  2
2  2   5  14  5
3  2   5  11  5
4  3   5   5  2
5  1  22  25  2
6  1  22  10  2
7  1  20   5  2
8  1  22   5  2
prft_path /home/hyunho/hmo/ACC_NAS/EA_log/prft_out_extpl_20_20_0_30.csv
pickle dump
log saved
Best individual:
[4, 5, 25, 2]
[[4, 5, 25, 2], [3, 5, 25, 2], [2, 5, 14, 5], [2, 5, 11, 5], [3, 5, 5, 2], [1, 22, 25, 2], [1, 22, 10, 2], [1, 20, 5, 2], [1, 22, 5, 2]]
Best individual is saved
EA time:  11899.355830192566
####################  EA COMPLETE / HOF TEST   ##############################


---------------------------------

number of trainable parameters:  622
score 193808.05
Result in RMSE:  20.21
BEST ind test RMSE 6.36
Average test RMSE 9.154
BEST ind test score 19094.37
Average test score 48307.5668
hypervolume_validation 4688952.084635735
hypervolume_test 4676772.68
------------------------------------------------------------




python3 plot_val_test_score.py --pop 100 --gen 0 -t 0 --bs 512

python3 enas_cnn_baseline.py -w 50 -s 50 -bs 512 -ep 30 -pt 30 -vs 0.2 -t 0 --pop 99 --gen 0 --obj "soo"

python3 enas_cnn_baseline.py -w 50 -s 50 -bs 512 -ep 30 -pt 30 -vs 0.2 -t 0 --pop 10 --gen 10 --obj "soo"

python3 enas_cnn_accel.py -w 50 -s 1 -bs 512 -ep 30 -t 0


python3 inference_cnn_aggr_ori.py -w 50 -s 50 -pt 30 

python3 inference_cnn_aggr_autotest.py -t 0 --pop 3 --gen 3 

python3 enas_cnn_baseline.py -w 50 -s 50 -bs 512 -ep 30 -pt 30 -vs 0.2 -t 0 --pop 3 --gen 3 --obj "soo"

python3 inference_cnn_pareto_autotest.py --pop 4 --gen 2 --obj "moo" -t 0

python3 enas_cnn_baseline.py -w 50 -s 50 -bs 512 -ep 30 -pt 30 -vs 0.2 -t 0 --pop 20 --gen 20 --obj "moo"